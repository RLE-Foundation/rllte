---
hide:
  - toc
---

# **RLLTE: Long-Term Evolution Project of Reinforcement Learning**



---

Inspired by the long-term evolution (LTE) standard project in telecommunications, aiming to provide development components for and standards for advancing RL research and applications. Beyond delivering top-notch algorithm implementations, **RLLTE** also serves as a **toolkit** for developing algorithms.

<div align="center">
<iframe width="560" height="315" src="https://www.youtube.com/embed/PMF6fa72bmE?si=oDLvQqxVrMP31Iqk" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
<br>
An introduction to RLLTE.
</div>

## **Why RLLTE?**
- ğŸ§¬ Long-term evolution for providing latest algorithms and tricks;
- ğŸï¸ Complete ecosystem for task design, model training, evaluation, and deployment (TensorRT, CANN, ...);
- ğŸ§± Module-oriented design for complete decoupling of RL algorithms;
- ğŸš€ Optimized workflow for full hardware acceleration;
- âš™ï¸ Support custom environments and modules;
- ğŸ–¥ï¸ Support multiple computing devices like GPU and NPU;
- ğŸ’¾ Large number of reusable benchmarks (See [rllte-hub](https://hub.rllte.dev));
- ğŸ‘¨â€âœˆï¸ Large language model-empowered copilot.

## **A `PyTorch` for RL**
RLLTE decouples RL algorithms into minimum primitives and provide standard modules for development. 

See [Fast Algorithm Development]() for detailed examples.
<div align=left>
<img src='./assets/images/structure.svg' style="width: 80%">
</div>


## **Project Evolution**
**RLLTE** selects RL algorithms based on the following tenet:

- Generality is the most important;
- Improvements in sample efficiency or generalization ability;
- Excellent performance on recognized benchmarks;
- Promising tools for RL.

## **Cite Us**
If you use **RLLTE** in your research, please cite this project like this:
``` tex
@article{yuan2022intrinsically,
  title={Intrinsically-motivated reinforcement learning: A brief introduction},
  author={Yuan, Mingqi},
  journal={arXiv preprint arXiv:2309.16382},
  year={2022}
}
```

<!-- Hsuanwu evolves based on reinforcement learning algorithms and integrates latest tricks. The following figure demonstrates the main evolution roadmap of Hsuanwu:
<div align=center>
<img src='./assets/images/roadmap.svg'>
</div>s -->

<!-- Please cite the following paper if you use Hsuanwu in your work, thank you!
```bibtex
@article{yuan2023rllte,
  title={Hsuanwu: Long-Term Evolution Project of Reinforcement Learning},
  author={Yuan, Mingqi and Luo, Shihao and Zhang, Zequn and Yang, Xu and Jin, Xin and Li, Bo and Zeng, Wenjun},
  journal={arXiv preprint arXiv:2311.15277},
  year={2023}
}
``` -->